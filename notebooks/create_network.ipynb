{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_nodes_from_user_data(G, user_data):\n",
    "#     for user_id in user_data['Id']:\n",
    "#         G.add_node(user_id)\n",
    "\n",
    "def add_nodes_from_user_data(G, user_data):\n",
    "    \"\"\"\n",
    "    Add nodes to the graph from user data, including attributes.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The graph to add nodes to.\n",
    "    - user_data (pandas.DataFrame): The user data containing the 'Id' column and other attributes.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for _, row in user_data.iterrows():\n",
    "        node_attributes = row.to_dict()\n",
    "        user_id = node_attributes.pop('Id')  # Remove the 'Id' as it will be the node identifier\n",
    "        G.add_node(user_id, **node_attributes)\n",
    "\n",
    "\n",
    "def preprocess_user_data(user_data, posts_data, comments_data, threshold):\n",
    "    # Calculate the number of posts per user\n",
    "    posts_count = posts_data['OwnerUserId'].value_counts()\n",
    "    \n",
    "    # Calculate the number of comments per user\n",
    "    comments_count = comments_data['UserId'].value_counts()\n",
    "    \n",
    "    # Combine the counts, filling in zeros for users who haven't posted or commented\n",
    "    combined_count = posts_count.add(comments_count, fill_value=0)\n",
    "    \n",
    "    # Filter users who meet the threshold\n",
    "    active_users = combined_count[combined_count >= threshold].index\n",
    "    \n",
    "    # Filter the user_data DataFrame to include only active users\n",
    "    active_user_data = user_data[user_data['Id'].isin(active_users)]\n",
    "    \n",
    "    return active_user_data\n",
    "\n",
    "\n",
    "def preprocess_post_data(posts_data, active_user_data):\n",
    "    # Filter posts to only those owned by active users\n",
    "    active_posts_data = posts_data[posts_data['OwnerUserId'].isin(active_user_data['Id'])]\n",
    "    \n",
    "    return active_posts_data\n",
    "\n",
    "\n",
    "def preprocess_comment_data(comments_data, active_user_data, active_posts_data):\n",
    "    # Filter comments to only those owned by active users\n",
    "    active_comments_data = comments_data[comments_data['UserId'].isin(active_user_data['Id'])]\n",
    "    \n",
    "    # Filter comments to only those on posts by active users\n",
    "    active_comments_data = active_comments_data[active_comments_data['PostId'].isin(active_posts_data['Id'])]\n",
    "    \n",
    "    return active_comments_data\n",
    "\n",
    "\n",
    "def add_edges_from_post_data(G, posts_data):\n",
    "    # Filter to only answers and drop NaNs\n",
    "    answers_data = posts_data[posts_data['PostTypeId'] == 2].dropna(subset=['ParentId', 'OwnerUserId'])\n",
    "\n",
    "    # Create a lookup table for question askers\n",
    "    question_askers = posts_data[posts_data['PostTypeId'] == 1].set_index('Id')['OwnerUserId']\n",
    "\n",
    "    # Iterate through answers\n",
    "    for answerer_id, question_id in zip(answers_data['OwnerUserId'], answers_data['ParentId']):\n",
    "        asker_id = question_askers.get(question_id)\n",
    "        # Check that answerer and asker are not the same\n",
    "        if asker_id is not None and answerer_id != asker_id:\n",
    "            G.add_edge(answerer_id, asker_id)\n",
    "\n",
    "\n",
    "def add_edges_from_comment_data(G, comments_data, posts_data):\n",
    "    # Drop NaNs\n",
    "    comments_data = comments_data.dropna(subset=['PostId', 'UserId'])\n",
    "\n",
    "    # Create a lookup table for post owners\n",
    "    post_owners = posts_data.set_index('Id')['OwnerUserId']\n",
    "\n",
    "    # Iterate through comments\n",
    "    for commenter_id, post_id in zip(comments_data['UserId'], comments_data['PostId']):\n",
    "        post_owner_id = post_owners.get(post_id)\n",
    "        # Check that commenter and post owner are not the same\n",
    "        if post_owner_id is not None and commenter_id != post_owner_id:\n",
    "            G.add_edge(commenter_id, post_owner_id)\n",
    "\n",
    "\n",
    "# Function to convert all Timestamps to strings in the graph data\n",
    "def convert_timestamps_to_strings(G):\n",
    "    for node, data in G.nodes(data=True):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, pd.Timestamp):\n",
    "                # Convert Timestamp to string\n",
    "                G.nodes[node][key] = value.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, pd.Timestamp):\n",
    "                # Convert Timestamp to string\n",
    "                G.edges[u, v][key] = value.strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data columns: Index(['Id', 'Reputation', 'CreationDate', 'LastAccessDate', 'Views',\n",
      "       'UpVotes', 'DownVotes', 'PostCount', 'CommentCount',\n",
      "       'AcceptedAnswerCount', 'AnswerCount', 'TotalActivity', 'AvgAnswerScore',\n",
      "       'AvgPostScore', 'AcceptedAnswerFraction', 'AnswerSentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create the network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Load user data\n",
    "with open('../data/raw/active_users_with_sentiment.pkl', 'rb') as file:\n",
    "    user_data = pickle.load(file)\n",
    "\n",
    "# # Print user data columns\n",
    "print('User data columns:', user_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post data columns: Index(['Id', 'PostTypeId', 'ParentId', 'AcceptedAnswerId', 'CreationDate',\n",
      "       'Score', 'ViewCount', 'Body', 'OwnerUserId', 'LastActivityDate',\n",
      "       'Title', 'Tags', 'AnswerCount', 'CommentCount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add edges from post (questions and answers) interactions\n",
    "\n",
    "with open('../data/raw/posts_typecasted_1.pkl', 'rb') as file:\n",
    "    posts_data_1 = pickle.load(file)\n",
    "with open('../data/raw/posts_typecasted_2.pkl', 'rb') as file:\n",
    "    posts_data_2 = pickle.load(file)\n",
    "with open('../data/raw/posts_typecasted_3.pkl', 'rb') as file:\n",
    "    posts_data_3 = pickle.load(file)\n",
    "with open('../data/raw/posts_typecasted_4.pkl', 'rb') as file:\n",
    "    posts_data_4 = pickle.load(file)\n",
    "\n",
    "# Combine all post data\n",
    "posts_data = pd.concat([posts_data_1, posts_data_2, posts_data_3, posts_data_4], ignore_index=True)\n",
    "\n",
    "# Print post data columns\n",
    "print('Post data columns:', posts_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment data columns: Index(['Id', 'PostId', 'Score', 'Text', 'CreationDate', 'UserId'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add edges from comment interactions\n",
    "\n",
    "with open('../data/raw/comments_typecasted_1.pkl', 'rb') as file:\n",
    "    comments_data_1 = pickle.load(file)\n",
    "with open('../data/raw/comments_typecasted_2.pkl', 'rb') as file:\n",
    "    comments_data_2 = pickle.load(file)\n",
    "with open('../data/raw/comments_typecasted_3.pkl', 'rb') as file:\n",
    "    comments_data_3 = pickle.load(file)\n",
    "with open('../data/raw/comments_typecasted_4.pkl', 'rb') as file:\n",
    "    comments_data_4 = pickle.load(file)\n",
    "with open('../data/raw/comments_typecasted_5.pkl', 'rb') as file:\n",
    "    comments_data_5 = pickle.load(file)\n",
    "\n",
    "# Combine all comment data\n",
    "comments_data = pd.concat([comments_data_1, comments_data_2, comments_data_3, comments_data_4, comments_data_5], ignore_index=True)\n",
    "\n",
    "# Print comment data columns\n",
    "print('Comment data columns:', comments_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 11810\n",
      "User data columns: Index(['Id', 'Reputation', 'CreationDate', 'LastAccessDate', 'Views',\n",
      "       'UpVotes', 'DownVotes', 'PostCount', 'CommentCount',\n",
      "       'AcceptedAnswerCount', 'AnswerCount', 'TotalActivity', 'AvgAnswerScore',\n",
      "       'AvgPostScore', 'AcceptedAnswerFraction', 'AnswerSentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add nodes to the graph\n",
    "add_nodes_from_user_data(G, user_data)\n",
    "\n",
    "# Print number of nodes\n",
    "print('Number of nodes:', len(G.nodes()))\n",
    "\n",
    "# Print user data columns\n",
    "print('User data columns:', user_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess posts data to only include posts from users in the network\n",
    "posts_data = preprocess_post_data(posts_data, user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 2718\n"
     ]
    }
   ],
   "source": [
    "# Add edges to the graph\n",
    "add_edges_from_post_data(G, posts_data)\n",
    "# Print number of edges\n",
    "print('Number of edges:', len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess comments data to only include comments from users in the network\n",
    "comments_data = preprocess_comment_data(comments_data, user_data, posts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 12150\n"
     ]
    }
   ],
   "source": [
    "# Add edges to the graph\n",
    "add_edges_from_comment_data(G, comments_data, posts_data)\n",
    "# Print number of edges\n",
    "print('Number of edges:', len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all Timestamps to strings\n",
    "convert_timestamps_to_strings(G)\n",
    "# Save the network\n",
    "nx.write_gexf(G, '../data/processed/network/network.gexf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network\n",
    "nx.write_gexf(G, '../data/processed/network/network.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
